---
title: "自问自答"
date: 2020-11-27
slug: "myself question and answer"
draft: false
tags:
- TECH
- Go
categories:
- TECH
---



# 一、数据库

## 数据库三范式

1. 必须要有主键
2. 每个字段都是最细粒度，无法被进一步拆分
3. 表数据不应该冗余。即一份数据不应该在多张表重复记录

## 数据库常见字段

1. 整型类型字段括号内数字意义
   - 代表的是最小显示长度，在数据库打开zerofill配置的前提下，不足位会在后边补0。因为默认是不打开，所以平常我们看到的实际上是不会自动补全的
2. 字符串类型字段括号内数字n的意义
   - 代表的是可插入的最大字符数。(<font color='red'>注意，不是字节数！一个中文为一个字符，但是占用 n*3 个字节</font>)
   - 当插入数超过最大字符数时，根据数据库模式的不同，会有不同表现
     - 严格模式，报错
     - 否则，自动截断
3. varchar 与 char 的区别
   1. char是固定长度的，不管字符有多少，都固定占用 n 个字符空间；而varchar是实际字符+1的空间占用。(<font color='red'>实际字符 + 1 < n</font>)
   2. 为什么varchar是 空间占用多了一个字节？
      - varchar属于变长字段，会额外使用1个字节来表示真正字符串占用的字节数
   3. varchar固定只用一个字节来记录字节长度？
      - 当最大字节数 <=  255，固定使用一个字节
      - 当最大字节数 > 255，则进一步看实际占用的字节数 L
        - L <= 127，还是使用一个字节
        - L > 127，使用两个字节

## 数据库模式

1. 数据处理方式差异
   - MySQL数据库不允许插入零日期，插入零日期会抛出错误而不是警告
   - 表中含字段TIMESTAMP列（如果未声明为NULL或显示DEFAULT子句）将自动分配DEFAULT '0000-00-00 00:00:00'（零时间戳）
   - 对于 char、varchar 类型字段，如果插入值长度超过了设置的最大值，宽松模式下会自动截断，而严格模式下，会直接报错！
2. 默认值差异
   - 5.6默认宽松
   - 5/7默认严格

## Innodb 跟 Myistam 的区别

1. Innodb支持事务
2. Innodb支持行级锁
3. 索引树节点数据不一样
   - innodb叶子节点是直接记录数据页，索引即数据。
   - myistam的叶子节点记录的是 主键+行号，需要根据行号再去找对应记录。相当于要多做一次回表操作
     - myistam的索引用的是定长格式，可以快速计算出偏移量，直接通过地址取数。所以其回表操作，实际上比innodb的回表效率高

## MySQL 数据页

1. MySQL中磁盘和内存交互的**基本单位是页**，也就是说MySQL是以页为基本单位来管理存储空间的，我们的记录都会被分配到某个页中存储。而一个页的大小一般是16KB，也就是16384字节

## Innodb 行数据结构

1. COMPACT行格式

![image_1c9g4t114n0j1gkro2r1h8h1d1t16.png-42.4kB](https://img-1302326115.cos.ap-guangzhou.myqcloud.com/img/169710e8fafc21aa)

2. Redundant行格式区别在于，额外信息不记录变长，也不记录null值，而是记录偏移量

   ![image_1ctfppb4c1cng1m8718l91760jde9.png-36.2kB](https://img-1302326115.cos.ap-guangzhou.myqcloud.com/img/169710e9ca9cbeb5)

3. Dynamic 

   - 这是5.7的默认格式，整体上跟COMPACT差不多，只是行溢出的处理有差异

     - 什么是行溢出？一个页一般是`16KB`，当记录中的数据太多，当前页放不下的时候，会把多余的数据存储到其他页中，这种现象称为`行溢出`。

     - 差异在于，不会在记录的真实数据处存储字符串的前768个字节，而是把所有的字节都存储到其他页面中，只在记录的真实数据处存储其他页面的地址。

       ![image-20201127122936403](https://img-1302326115.cos.ap-guangzhou.myqcloud.com/img/image-20201127122936403.png)

4. Compressed

   - 跟Dynamic 很像，区别在于Compressed行格式会采用压缩算法对页面进行压缩。

## 事务

1. 事务隔离级别

   - 读已提交
   - 读未提交
   - 可重复读
   - 序列化

2. 解决什么问题？

   ![image.png](https://img-1302326115.cos.ap-guangzhou.myqcloud.com/img/1605602217689-ffbf2e35-bbdd-46bd-b1b6-6ce64c29f420.png)

3. 幻读与不可重复读

   - 幻读是每次读的结果总数不一样，针对的是insert, `幻读`强调的是一个事务按照某个相同条件多次读取记录时，后读取时读到了之前没有读到的记录。
   - 不可重复读是每次读的结果内容不一样，针对的是update/delete操作

4. 可重复读是怎么实现的

   - 创建事务那一刻，记录当前活跃的事务(已创建，未提交)，并拿到其最低位与最高位；读数时，根据每条记录的tr id判定
     - 小于最低位，即创建事务前已提交，可见
     - 高于最高位，即创建事务后才发生，不可见
     - 在区间内，如果能找到，说明创建事务的时候还没有提交，不可见；否则，可见
   
5. 可重复读如何避免幻读？

   - 在MySQL的InnoDB引擎中，通过间隙锁（gap lock）+行锁组成的next-key lock，在可重复读级别下解决了幻读的问题。

## 索引

1. 最左前缀
2. 索引数据结构
   - b+树
   - 叶子节点存放数据页，数据页内及数据页间的数据是有序的
     - 每次数据插入都得排序，所以主键提倡使用有序的值，避免页迁移带来的开销
   - 基于主键的索引叫聚簇索引，索引即数据
   - 二级索引只记录索引列字段及主键，要查询更多数据时，需要回表
3. 索引为什么快？B+ 树的优点，为什么快？
   - B+树层级可控，2-4层，遍历次数少，查询效率高
   - 只有叶子节点记录了数据，读写代价低。因为内部节点不存放数据，内存占用少，可以尽可能得放在一个盘上，进一步避免了I/O开销
   - b+树查找效率稳定为log N，因为从根节点到叶子节点的长度是固定的
   - 由于叶子节点数据是有序的，范围查找更方便，遍历时效率更高。
4. 都有哪些树
   - 二叉树，只会有两个子节点。
   - 满二叉树，除了叶子节点，每个父节点都有两个子节点。
   - 完全二叉树，最下层节点从左到右排列，且除掉最后一层后，满足 满二叉树概念
   - 平衡树，父节点的左子树和右子树的高度之差不大于1
   - 完全平衡二叉树，一个满二叉树同时满足平衡树的定义
5. B+树与红黑树对比
   - 红黑树只能二叉，数据量大的时候，树的深度也会很大，由此带来的I/O开销也会很大。

## MVCC

1. 版本链
   - 每次对记录进行改动，都会记录一条`undo日志`，update操作时，还会有一个`roll_pointer` 属性，则每次 改动的undo日志可以通过这个属性串成一张链表；（注意，每个undo日志都有记录对应事务id）
2. ReadView
   - 解决的核心问题是，判断版本链中的哪个版本是当前事务可见的，主要是跟事务隔离级别配合使用
   - `ReadView`中主要包含4个比较重要的内容
     - `m_ids`：表示在生成`ReadView`时当前系统中活跃的读写事务的`事务id`列表。
     - `min_trx_id`：表示在生成`ReadView`时当前系统中活跃的读写事务中最小的`事务id`，也就是`m_ids`中的最小值。
     - `max_trx_id`：表示生成`ReadView`时系统中应该分配给下一个事务的`id`值。
     - `creator_trx_id`：表示生成该`ReadView`的事务的`事务id`。
   - 如果某个版本的数据对当前事务不可见的话，那就顺着版本链找到下一个版本的数据，继续按照上边的步骤判断可见性，依此类推，直到版本链中的最后一个版本。如果最后一个版本也不可见的话，那么就意味着该条记录对该事务完全不可见，查询结果就不包含该记录。
3. 所谓的`MVCC`（Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用`READ COMMITTD`、`REPEATABLE READ`这两种隔离级别的事务在执行普通的`SELECT`操作时访问记录的版本链的过程，这样子可以使不同事务的`读-写`、`写-读`操作并发执行，从而提升系统性能。
4. `READ COMMITTD`、`REPEATABLE READ`这两个隔离级别的一个很大不同就是：生成ReadView的时机不同，
   - READ COMMITTD在每一次进行普通SELECT操作前都会生成一个ReadView
   - 而REPEATABLE READ只在第一次进行普通SELECT操作前生成一个ReadView，之后的查询操作都重复使用这个ReadView就好了。

## SQL 调优

# 二、Http

## 三次握手与四次挥手

1. 概念
   - 三次握手
     - 客户端发请求到服务端
     - 服务端收到后，发送ACK
     - 客户端收到服务端的ACK，返回ACK
   - 四次挥手
     - 客户端发请求给服务端
     - 服务端返回ACK，客户端关闭连接
     - 服务端发请求给客户端
     - 客户端返回ACK，服务端关闭连接
2. 为什么要三次握手？
   - 确保双方的收发能力正常
   - 约定本次连接的初始序列号。一定程度上可以处理在网络中延迟送达的数据
3. 为什么要四次挥手？
   - 从传输层TCP看，接收方只能知道发送方要关闭连接了，但是无法替上层应用决定是否要把这边的连接也一起关闭了。
   - 从应用层HTTP看，客户端要建立连接时，服务端可以立马给建立，所以三次握手就够了；而关闭连接时，由于服务端可能还有数据在发送，所以不可能客户端一说要关，立马就关。从Http角度看4次挥手
     - 客户端： 我要关了！
     - 服务端：知道了，等我发完这波数据！
     - 服务端：我发完了，那可以关了
     - 客户端：好的，我关了。(为了确保服务端有收到这个信息，所以要等2MSL；因为如果丢失了，服务端会要求重传)
4. 过程状态
   - SYN_RCVD状态
     - 客户端发起建立连接请求，服务端返回ACK；即第二次握手完成时
   - ESTABLISHED状态
     - 客户端返回ACK，即第三次握手完毕，连接正式建立。
   - Time Wait
     - 四次挥手过程中，服务端给客户端发送FIN，客户端会进入Time Wait，并回复ACK，然后等待 2 MSL后， 客户端也进入 CLOSED 状态
     - 为什么会有？
       - 确保可以正确的关闭连接
       - 防止网络延迟的数据被复用。如果立马关闭连接，可以在2MSL内，连接被复用，导致下一个连接处理了上一个连接的延迟数据。2MSL的原因在于，数据包最长存活时间为MSL，设置为其2倍，确保一来一回的时间。
5. Connection reset by peer 错误
   - 简单来说，就是连接关闭后的读与写操作引起的
   - 常见场景
     - 最常见的是连接数满了之后的连接被释放。根据server端配置项差异，可能会直接丢弃这个请求，也可能会关闭一些连接。对应就可能引起`read time out` 或者` Connection reset by peer`
     - 浏览器关闭，没有通知到服务端
     - 防火墙限制
     - JSP buffer

## TCP / IP 模型

![image.png](https://img-1302326115.cos.ap-guangzhou.myqcloud.com/img/1604400280914-f84c5584-6369-45a9-b735-edaf93cd3de8.png)

## TCP / UDP的区别

1. TCP的需要建立连接，而UDP是无连接的
   - UDP一定是无连接的吗？
2. TCP是面向字节流的，而UDP是面向报文的
3. TCP是可靠的，而UDP不保证数据传输的可靠性
   - 为什么说TCP是可靠的
     - 保证数据顺序
     - 重传
4. TCP首部开销要比较大
5. TCP只能一对一连接，而UDP可以一对多

## HTTP1/HTTP2/HTTPS

1. http 数据包格式
   - request/response line(请求方式、请求路径、版本号)
     - Date
     - Cache-Control
     -  Connection
   - request/response header
   - request/response body
2. http2的优化
   - 多路复用
   - 头部压缩
   - 服务端推送
3. https的加密流程
   - 客户端请求服务器获取证书公钥
   - 客户端(SSL/TLS)解析证书（无效会弹出警告）
   - 生成随机值
   - 用公钥加密随机值生成密钥
   - 客户端将秘钥发送给服务器
   - 服务端用私钥解密秘钥得到随机值
   - 将信息和随机值混合在一起进行对称加密
   - 将加密的内容发送给客户端
   - 客户端用秘钥解密信息

## HTTP 请求码

以 `2xx` 为开头的都表示请求成功响应。

| 状态码 | 含义                                                         |
| ------ | ------------------------------------------------------------ |
| 200    | 成功响应                                                     |
| 204    | 请求处理成功，但是没有资源可以返回                           |
| 206    | 对资源某一部分进行响应，由Content-Range 指定范围的实体内容。 |

以 `3xx` 为开头的都表示需要进行附加操作以完成请求

| 状态码 | 含义                                                         |
| ------ | ------------------------------------------------------------ |
| 301    | 永久性重定向，该状态码表示请求的资源已经重新分配 URI，以后应该使用资源现有的 URI |
| 302    | 临时性重定向。该状态码表示请求的资源已被分配了新的 URI，希望用户（本次）能使用新的 URI 访问。 |
| 303    | 该状态码表示由于请求对应的资源存在着另一个 URI，应使用 GET 方法定向获取请求的资源。 |
| 304    | 该状态码表示客户端发送附带条件的请求时，服务器端允许请求访问资源，但未满足条件的情况。 |
| 307    | 临时重定向。该状态码与 302 Found 有着相同的含义。            |

以 `4xx` 的响应结果表明客户端是发生错误的原因所在。

| 状态码 | 含义                                                         |
| ------ | ------------------------------------------------------------ |
| 400    | 该状态码表示请求报文中存在语法错误。当错误发生时，需修改请求的内容后再次发送请求。 |
| 401    | 该状态码表示发送的请求需要有通过 HTTP 认证（BASIC 认证、DIGEST 认证）的认证信息。 |
| 403    | 该状态码表明对请求资源的访问被服务器拒绝了。                 |
| 404    | 该状态码表明服务器上无法找到请求的资源。                     |

以 `5xx` 为开头的响应标头都表示服务器本身发生错误

| 状态码 | 含义                                                         |
| ------ | ------------------------------------------------------------ |
| 500    | 该状态码表明服务器端在执行请求时发生了错误。                 |
| 503    | 该状态码表明服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。 |

## RPC与HTTP

1. RPC 可以基于TCP协议，也可以基于HTTP协议
   - grpc 是基于http 2的
2. RPC 报文体积小，传输效率高
3. RPC 采用thrift来实现高效的二进制传输，http的json序列化对性能消耗大
   - grpc使用ProtoBuf
4. RPC自带负载均衡
   - groc 路由选择
     - RandomSelect： 随机选择
     - RoundRobin: 轮转的方式
     - WeightedRoundRobin: 基于权重的平滑的选择
     - ConsistentHash： 快速一致哈希
5. RPC自带服务治理
   - [grpc](https://www.bookstack.cn/read/go-rpc-programming-guide/part3-chapter9.md)
     - 统计， MetricsPlugin
     - 限流， RateLimitingPlugin

## Http最大连接数

1. 客户端基于端口，最多只有65535；而又因为有1024以下的端口是系统内核要用的，所以实际更少
2. 服务端理论上是基于 ip * port，最多有2^48次方。但是处理1024端口限制之外，服务端还进一步受到文件句柄，内存等限制

## Http 缺点

1. 无状态
   既然服务器没有记忆能力，它就无法支持需要连续多个步骤的事务操作。每次都得问一遍身份信息，不仅麻烦，而且还增加了不必要的数据传输量。由此出现了 Cookie 技术。

2. 明文
   HTTP 协议里还有一把优缺点一体的双刃剑，就是明文传输。明文意思就是协议里的报文（准确地说是 header 部分）不使用二进制数据，而是用简单可阅读的文本形式。因此极其不安全，可以被监听和被窥探。因为无法判断通信双方的身份，不能判断报文是否被更改过。

3. 性能
   HTTP 的性能不算差，但不完全适应现在的互联网，还有很大的提升空间。

## 如何设计一个应用层的http协议

## 安全攻击

1. xml攻击
2. syn flood攻击
   1. 原理，发送大量的建立连接请求，消耗掉服务端的TCB，从而引起服务端的资源被严重浪费
   2. 防范
      - 延缓TCB分配，等到真正建立起连接了才分配
        - syn cache
        - syn cookie
      - 使用防火墙

# 三、Redis

## Redis 数据类型

1. 都有哪些类型?底层是什么数据结构
   - string
   - list
   - set
   - zset
     - 数据量少的时候使用ziplist
     - 多的时候用跳表
   - hash
2. 用-*+什么类型可以做字典
   - hash
   - 压缩列表
3. 什么是跳表？什么是压缩列表
   - 跳表，最底层数据还是双向链表，再基于一个可配置的最大值，随机生成一个层级，第几层则跳过节点，把两个节点连接起来，用于范围查找时效率更高
     - 实际使用时，是从最上层，找个每个数值区间后，继续往下一层查找
     - ![img](https://pic2.zhimg.com/80/v2-406ac352da4f3c45da01ba5e2c168d9d_720w.jpg)
   - 压缩列表，底层数据结构是数组，但是不同于数组，压缩列表的每个节点值的长度是不定长的。
     - 压缩列表作字典时，先把key放到尾部，再把value放到尾部，所以从尾部开始遍历，每两个相邻的节点就是一个kv结构
     - 压缩列表跟数组的区别不只是长度不定长，还有一点是他每个节点都多了一个length的属性
     - ![image-20201201231546771](https://img-1302326115.cos.ap-guangzhou.myqcloud.com/img/image-20201201231546771.png)
4. 字典怎么扩容？
   - 根据负载因子来决定是扩容还是缩容
   - 分配大小
     - 扩容：分配第一个大于ht[0].used*2的2^n大小的空间*
     - 收缩：分配第一个大于等于ht[0].used的2^n大小的空间
   - 处理时机(先标记rehash)
     - 查找：先查找ht[0]，若找不到则查找ht[1]
     - 删除，更新：会同时对ht[0]和ht[1]执行相同的操作 
     - 插入：直接在ht[1]中进行插入操作
5. 哈希冲突怎么解决
   - 开放寻址法
     - 线性探查
     - 平方探查
     - 双散列
   - 链表法
6. 满足什么条件的数据类型才可以作为Redis的key

## Redis 内存淘汰机制

1. 内存淘汰
   - 直接报错
   - 针对所有数据
     - 随机淘汰
     - 基于LRU
   - 针对有过期时间的数据
     - 随机淘汰
     - 即将过期的优先淘汰
     - LRU
   
2. 怎么设计一个LRU算法
   - 用到了什么数据结构？
   
     - 双向链表
     - 哈希表
   
   - 怎么读？怎么写？
   
     - 读的时候，先根据key在哈希表中找到链表，再从链表取数
     - 写的时候，先读，能读到就移动到头(先删再直接往头添加)，否则，直接放到头
   
   - 链表存的是什么？哈希表存的是什么？
   
     - 双向链表存真实数据(不是最近一次访问的时间戳，而是记录了空闲时间idle time，越小，意味着是最近被访问的。这样可以避免做时间戳的比较。)
     - 哈希表用来做快速查询
   
   - 手撸！
   
     - ```go
       package main
       
       func main() {
       }
       
       
       type LinkNode struct {
       
       	key,val int
       	pre,next *LinkNode
       
       }
       type LRUCache struct {
       
       	m map[int]*LinkNode
       	cap int
       	head, tail *LinkNode
       }
       
       func Constructor(cap int) LRUCache {
       	head := &LinkNode{0,0, nil, nil}
       	tail := &LinkNode{0,0, nil, nil}
       	head.next = tail
       	tail.pre = head
       	return LRUCache{make(map[int]*LinkNode), cap , head, tail}
       }
       
       func (this *LRUCache) Add(node *LinkNode) {
       	head := this.head
       	node.next = head.next
       	head.next.pre = node
       	node.pre = head
       	head.next = node
       }
       
       
       func (this *LRUCache) Remove(node *LinkNode) {
       	node.pre.next = node.next
       	node.next.pre = node.pre
       }
       
       
       func (this *LRUCache) MoveToHead(node *LinkNode) {
       	this.Remove(node)
       	this.Add(node)
       }
       
       
       func (this *LRUCache) Get(key int) int {
       	m := this.m
       	// 有数据，挪到头
       	if v,ok := m[key]; ok {
       		this.MoveToHead(v)
       		return v.val
       	}
       	return -1
       }
       
       func (this *LRUCache) Put(key,value int)  {
       	m := this.m
       	tail := this.tail
       	// 有数据，挪到头
       	if v,ok := m[key]; ok {
       		v.val = value
       		this.MoveToHead(v)
       		return
       	}
       	v := &LinkNode{key,value,nil,nil}
       	if len(m) == this.cap {
       		delete(m, tail.pre.key)
       		this.Remove(tail.pre)
       	}
       	this.Add(v)
       	m[key] = v
       }
       ```
   
3. REDIS的LRU算法有什么不一样？有什么好处？

   - redis 的LRU并没有用链表来存放，因为redis觉得太占内存
   - redis 在基础数据类型的基础上，用了一个对象来记录idle time。即给每个key增加了一个额外增加了一个24bit的字段，用来存储该key最后一次被访问的时间。
   - redis 采用随机采样法，每次随机取5个(可配置，默认为5)key，从中淘汰掉最近最少被使用的
   - redis 3.0有进一步的优化，实现了候选池方案，则在淘汰的时候，可以直接跟池中比较即可，删除池中最大的一个key；这样可以提高淘汰羡慕，避免每次都做重复计算

4. LRU与LFU算法优缺点

   - LRU 是淘汰最近最少被使用，如果有个key很久没被访问，正好在触发淘汰前被访问到了，也不会被淘汰
   - LFU 是淘汰访问频率低的，则如果有个历史热点key，则可能因为曾经访问频率很大，导致一直没被淘汰

## 缓存雪崩、击穿及击透

1. 雪崩
   - redis宕机，导致一瞬间有大量请求被打到数据库层面
   - **解决：**
     - 事前
       - 主从 + 哨兵集群保障高可用
     - 事中
       - 熔断、限流、降级。可行情况下，返回本地缓存
     - 事后
       - redis数据持久化，方便重启快速恢复
2. 击透
   - 每次请求的key都无法命中缓存，则每次都会被透传到数据库层面
   - **解决：**
     - 第一次缓存没命中，给缓存赋一个特殊值
     - 布隆过滤器
3. 击穿
   - key失效瞬间，该热点key的压力直接打到了数据库层面
   - **解决：**
     - 永不过期
     - 互斥锁，让唯一一个线程重设redis
4. 怎么实现redis高可用
   - 主从+哨兵

## Redis数据一致性

1. 先删缓存，再更新数据库

## Redis 分布式锁应用场景

1. 项目中的应用
2. 秒杀场景设计
   - 前端
     - 按钮控制，设置可点击时间及间隔时间
   - 后端
     - 恶意请求拦截过滤
     - 基于功能拆解微服务，压力负载
     - 提前使用redis做热点数据缓存，可以采用本地缓存加载静态数据
     - 限流削峰
     - 商品扣减在redis层做完快速响应，再异步交由数据库做写入
3. 还有哪些分布式锁
   - zk
   - redis
   - mysql

# 四、Linux

## select / epoll 

1. 概念
   - select跟epoll 本质上都是一种多路复用的技术，可以同时处理更多的连接。
   - 本质上是使用一个进程来监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。
   - epoll 是select的升级版， select是无差别轮询，它只知道有事件发生了，但是不知道是什么事件，所以需要轮询所有流；而epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是事件驱动（每个事件关联上fd）的。
2. 原理
   - 在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，每次轮询都要把事件的描述符(FD)拷贝到内核，并且还要遍历所有FD；
   - **epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知**。
3. 优缺点
   - epoll是以回调的方式放到就绪队列，每次被唤醒时只需要查看一下就绪队列即可，节省了大量的CPU时间。同时监视的描述符数量不受限制。IO的效率不会随着监视fd的数量的增长而下降。
   - FD很多的时候，select的拷贝以及遍历开销会很大，而epoll不需要拷贝，epoll只有在调用函数创建句柄的时候会拷贝一次，同时，epoll使用mmap减少复制开销。
   - epoll 使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。

## 堆分配与栈分配

1. 内存策略
   a. 静态 Static，这种数据目标在编译时就为他们分配固定的内存。
   b. 栈式 Stack，分配是在运行时执行的，但是大小是在编译时确定的。
   c. 堆式 Heap，在运行的时候，请求操作系统分配给自己内存，由于从操作系统管理的内存分配，所以在分配和销毁的时候都要占用时间，因此效率低下。

2. 优缺点比较
a. 堆
ⅰ. 优点：编译时不必知道要从堆里分配多少存储空间，也不必知道存储的数据要在堆里停留多长时间，因此堆存储数据时，灵活性比较大；
ⅱ. 缺点： 在运行时动态分配内存，所以内存的存取速度较慢；在分配和销毁的时候都要占用时间；GC压力大；容易产生内存碎片。
b. 栈
ⅰ. 优点：栈的存取速度比堆要快；栈数据可以共享；函数返回直接释放，不会引起垃圾回收，对性能没有影响
ⅱ. 缺点：栈的数据大小与生存期必须是确定的，缺乏灵活性。

## Linux页

1. 页概念
   - linux内存管理的最小单位
2. 页置换
   - OPT，淘汰未来很长一段时间不被使用，或者永久不被使用的
   - FIFO，在内存待得时间长，越先被淘汰
   - LRU，最近最少被使用的，优先淘汰

## 基础命令

## Docker

### docker原理

1. 资源隔离，使用Linux命名空间来隔离不同容器进程
2. 资源限制，使用Linux cgroup来限制各个进程所占用的资源(CPU、内存等)
3. 存储驱动AUFS，借助Linux存储驱动，可以在一个基础文件系统上“增量式”叠加文件，从而实现了镜像分层

### docker file

1. 镜像太大怎么办
   - 在满足需求的前提下，尽量选择小的基础镜像
   - docker file一个RUN指令就会生成一层，尽量合并多个RUN指令，是降低镜像大小最有效的方式
   - 下载的安装包，安装完成后，记得要删除
   - 多阶段构建，build跟run分开

### docker指令

### windows怎么运行docker

在windows上模拟出linux环境， 然后再运行

# 五、算法

## 排序

1. 有哪些基础排序算法
   - 冒泡排序
     - **思路，**首先从数组的第一个元素开始到数组最后一个元素为止，对数组中相邻的两个元素进行比较，如果位于数组左端的元素大于数组右端的元素，则交换这两个元素在数组中的位置，则可以拿到升序的结果。
   - 选择排序
     - **思路，**首先在未排序部分中拿到第一个元素，作为起始位置，然后，再从起始位置开始，找到比起始位置小的数据中的最小下标，然后跟起始位置交换，以此类推，则可以拿到升序的结果。
   - 插入排序
     - **思路，**记录当前位置的值A，再从当前位置从后往前遍历，如果发现比记录值A小的位置B，则B开始的元素往后移，把记录A插入位置B
   - 希尔排序
     - 插入排序的优化版
     - 其核心思路是把记录按一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。
   - 快速排序
     - **思路，**
       - 以当前数组的第一个元素作为基准值；
       - 先从后往前找，找到第一个比基准值小的数，则停止，并把这个数放到最前边；
       - 再从前往后找，找到第一个比基准值大的数，则停止，并把这个数放到最后边；
       - 缩小数据范围，递归处理
   - 归并排序
     - **思路**
       - 找到中间值，把集合切分成两块；递归切分，直到集合只有两个元素为止
       - 对每个小集合内部做排序，再将所有小集合一起做排序
   - 堆排序
     - **思路，**利用堆存放，将待排序列构造成一个大顶堆(或小顶堆)，整个序列的最大值(或最小值)就是堆顶的根结点，将根节点的值和堆数组的末尾元素交换，此时末尾元素就是最大值(或最小值)，然后将剩余的n-1个序列重新构造成一个堆，这样就会得到n个元素中的次大值(或次小值)，如此反复执行，最终得到一个有序序列。
2. 时间复杂度
   - ![image.png](https://img-1302326115.cos.ap-guangzhou.myqcloud.com/img/1605772754268-ee56e641-c181-4de9-a651-b5633c89fbf1.png)

## 链表

1. 两个单向链表相交
   - 什么形状？
     - ![这里写图片描述](https://img-1302326115.cos.ap-guangzhou.myqcloud.com/img/20171224151324826)
   - 判定是否有相交
     - 从头开始遍历，取第一个相同的节点即可
   - 求交集
     - 直接判断两个链尾节点是否相同即可

## 回文

## 最小k个数

## 矩阵

## 位运算

# 六、Map

## 数据结构

 key-value键值对

## 数据定位

1. 对key做哈希
2. 取哈希结果的低 B 位则可以定位到在哪个桶
3. 取哈希结果的高 8 位则可以定位到在桶中的哪个位置

![go-map-key-find](https://img-1302326115.cos.ap-guangzhou.myqcloud.com/img/AKiMB7cZLgpkjqQ.jpg)

## 哈希冲突

1. 什么是哈希冲突
   - 哈希冲突是指哈希函数算出来的地址被别的元素占用了
2. 如何解决？
   - 开放寻址法
     - 线性探查法
     - 平方探查法
     - 双散列
       - 一个用来定位位置
       - 一个用来随机生成一个固定增量
   - 链表法
     - 冲突的元素记录在一条单向链表上
   - 再哈希
     - 冲突时，使用另一个哈希算法再做一次哈希
   - 建立公共溢出区

## 扩容

1. 什么时候触发扩容？扩容多少?
   - 赋值时，检查是否需要扩容
   - 扩容时机
     - 装载因子超过阈值，源码里定义的阈值是 6.5。做翻倍扩容
     - overflow 的 bucket 数量过多。做等量扩容
2. 什么时候做扩容数据迁移
   - 赋值跟删除时，会检查是否在扩容中，是则协助搬运两次

# 七、KAFKA

## kafka为什么性能好

1. 磁盘持久化，IO顺序读取效率高。而且是先写入 Page Cache，page cache是在内存中操作，内存中顺序写的操作要比磁盘快大约10倍。
2. Linux 零拷贝机制，避免重复复制数据，对消费端的性能有极大提升
   - 零拷贝实现原理？在linux中，这个函数是sendfile，可以将数据从页面缓存发送到socket
3. Topic 多分区可以提高并发能力
4. 数据批量发送，有效降低IO压力
   - 缓存数据放在哪？发送到客户端的消息缓冲池（Accumulator） 中，最后交由Sender线程发往broker端。
5. 数据压缩，可以减少数据传输量， 减轻对网络传输的压力

## 集群选举(Raft算法)

整个算法的实现分为三个阶段，主要分为选主阶段、日志复制阶段以及安全状态。（[参考资料](https://blog.csdn.net/qq_37142346/article/details/90523387)）

1. 选主阶段
   - 对于每一个实例都有一个`server id`以及`timeout`，每一个实例会随机sleep一个timeout，然后开始投票，都去选举那个最大的`serverid`,如果有超过半数以上的实例同意，那么将其选举为leader。
     - 之所以随机sleep一个time，是因为这样可以加快选举的流程，在一般情况下，只要网络状态良好，先timeout的实例先进行选举，这样只需要一轮选举就选举出leader，避免了由于相互选举而再次进入选举的情况。
   - 主节点和其他子节点之间通过心跳机制保持联系，如果在一段时间内收不到心跳报告，则将该节点判为故障。
     - 如果从节点故障，那么待故障恢复之后，就会去主节点同步日志进行故障恢复。
     - 如果主节点故障，那么会重新进入选举阶段，每一个实例会将当前的term加1然后进行投票，如果接收到的投票小于自己的term，那么投反对票，即选举自己。最后统计大于半数的节点选举为leader，如果选举失败，则会将当前term再加1进行选举，直到选举成功。
2. 日志复制阶段
   - 在选举完成之后，客户端与leader交互写入数据，这时leader会在自己的log的第一个空位index中写入数，接着，通过`AppendEntries RPC`把当前index的entry以及`lastest commiteid`发送给每一个follower节点
   - 如果follower接收到的`lastest commiteid`等于当前实例的，代表<=该ID的所有entry已经被`commit`，此时follower返回true，否则返回false。
     - 如果超过半数的follower向leader返回true，那么代表当前entry写入成功。
     - 对于返回false的实例，可能是因为网络原因或者故障恢复的原因，数据没有正确同步，此时leader会从最后一个entry开始向前遍历，知道找到故障实例对应的entry，然后开始恢复数据。
3. 安全状态
   - 集群不下线，修改配置后自动更新
     - Raft采用了`joint consensus`机制将整个更新阶段划分为两个阶段，地一个阶段是之前的旧配置阶段，这个阶段不能处理客户端的请求，当该阶段commit之后，将会过渡到下一个阶段，即支持新配置的阶段。
   - 快照机制
     - 对于集群中的每一个实例，都会维护着一个快照，这个快照中保存了最后提交的index，当前term，以及当前数据的最后更新值，如图中保存x,y的最近状态的值x=0，y=9，在发生故障的时候，就会通过读取快照从而快速恢复到之前的状态。
     - ![在这里插入图片描述](https://img-1302326115.cos.ap-guangzhou.myqcloud.com/img/20190524213251632.png)

## 分区与消费者的关系

1. 分区数 > 消费者数，消费者一一对应一个分区，多余分区处理闲置状态
2. 分区数 = 消费者数，消费者一一对应一个分区
3. 分区数 < 消费者数，每个分区起码有一个消费者相关联，多余的消费者会随机关联一个分区，即一个分区可能有多个消费者同时监听

## 消费者组工作原理

## Push ACK

1. 0，只管发，不管结果，发完就完事了
2. 1，管发，稍微管一管是否成功给到leader，会堵塞，可能会丢，如果还没成功同步到副本，leader节点就宕机了的话。
3. -1(ALL)，管发，而且必须是leader + 副本节点都成功备份了，才会收到成功的结果，一般是异步通知结果。

## 重复消费

重复消费的核心问题在于offset没有被正确提交。但是在具体场景中，可能会有各种情况。比如说：

1. 系统宕机，导致进程被强制kill，此时已消费的数据还没来得及提交offset
2. 消费后数据处理耗时过长，超过了session timeout，导致partition断开，offset无法提交
3. 非手动提交时，消费后数据处理耗时过程，导致超过了poll心跳时间，导致服务端认为这个消费者已死，所以会从消费组中将其移除，此后的offset无法提交
4. 新建消费者组去监听topic，如果没有指定起点offset，则默认是从头开始，则可能会有重复

## 消息丢失

消息丢失可能是生产者的问题，也可能是消费者的问题。

一般来说，生产者会出现消息丢失，主要原因是没有把ACK设置为all，则在消息并没有完全到达broker的前提下，误判为推送成功。

1. 数据还在page cache中，系统宕机
2. 消息体过大，无法被broker接收.(取决于配置项)
3. 节点宕机，数据还没来得及备份

消费者最容易出问题的是设置了自动提交offset，但是又在消费方法中处理过多的耗时逻辑，导致在到了心跳间隔时间时，实际上还没处理完毕，但是被自动提交了offset，默认为已经消费成功。

Kafka数据保留时间配置，也是一个容易被忽略的点。

# 八、Go

## 面向并发的内存模型

1. 基于CSP模型的并发编程

2. 独有的基础调度单位，Goroutine协程

   - 什么是协程？
     - Goroutine是Go语言特有的并发体，是一种轻量级的线程，由go关键字启动。
     - Go程序运行时。会有自己的调度器，专门来管理协程的调度
     - go1.4版本之前，Goroutine是半抢占式的，由一些特有的场景触发协程调度后，会检查每个协程的运行时间，判定是否堵塞，是否需要让出资源？则可能出现有协程一些占有着资源无法释放的情况；1.4版本之后，通过channel的通信机制，实现了真正的抢占式调度
   - 协程与线程的区别
     - 内存占用更少。一个goroutine 栈内存消耗为 2 KB，而一个thread 需要消耗 1 MB 栈内存。
     - Thread需要跟操作系统打交道，属于内核级的应用；而 goroutine 是由 Go runtime 负责管理的，属于用户级的应用，因此其创建和销毁的成本要远小于thread 。
     - 从切换成本的角度看，由于goroutine 只需要保存3个寄存器，而thread所需要保存要多得多，因此，显然goroutine的切换成本更低。一般而言，线程切换会消耗 1000-1500 纳秒，而goroutine只需要200纳秒。
     - 线程由CPU调度，是抢占式的；协程由用户态调度，是协作式的。(goroutine 调度的事情是由 Go runtime 来做，并非由用户控制，因此从用户表现来看，会觉得是抢占式，但实际上它是协作式的)
   - 协程与线程的关系（ GPM 模型）
     - 基础概念
       - G（Goroutine）：一个G代表一个goroutine
       - P（Process）：处理器，用来管理和执行goroutine，一个P代表了M所需的上下文环境
       - M（Machine）：内核级线程，一个M代表了一个内核线程，等同于系统线程
     - GMP模型
       - 简单的来说，一个G的执行需要M和P的支持，一个M在与一个P关联之后形成了一个有效的G运行环境【内核线程 + 上下文环境】，每个P都会包含一个可运行的G的队列。 每个 M 必须依附于一个 P，每个 P 在同一时刻只能运行一个 M。
       - Go 程序启动后，会给每个逻辑核心(CPU核数)分配一个 P（Logical Processor）；同时，会给每个 P 分配一个 M（Machine，表示内核线程），这些内核线程仍然由 OS scheduler 来调度。Go scheduler 使用 M:N 模型，在任一时刻，M 个 goroutines（G） 要分配到 N 个内核线程（M），这些 M 跑在个数最多为 GOMAXPROCS 的逻辑处理器（P）上。

   3. 原子操作
      - go语言提供了sync包，其中有用于控制并发原子性的语法，具体见下边的Sync包讲解。
   4. 顺序一致性内存模型
      - 为了保障并发数据的处理顺序准确，顺序一致性的内存模式是必不可少的
      - 在go语言中，主张用通信来共享内存，其channel语法，正式为此而生。
        - 没有缓冲区的channel，必须同时存在收发动作，二者缺其一，都会造成阻塞
        - 有缓冲区的channel
          - 缓冲区满之前，发送动作不会阻塞
          - 缓冲区为空的时候，接收动作会阻塞
      - channel语法的一个最关键的特性是，写一定发生在读之前！
   5. 初始化顺序
      - Go程序的初始化和执行总是从`main.main`函数开始的。但是如果`main`包里导入了其它的包，则会按照顺序将它们包含进`main`包里
      - 当一个包被导入时，如果它还导入了其它的包，则先将其它的包包含进来，然后创建和初始化这个包的常量和变量。然后就是调用包里的`init`函数
        - 匿名import的原理
        - 什么是匿名import？当你只需要用到一个包的常量、变量以及init函数，但是实际代码又不需要调用其他东西时，可以采用匿名import，避免编译报错。比如说，mysql driver包的引入，`_ "github.com/go-sql-driver/mysql"`
      - 最终，在`main`包的所有包常量、包变量被创建和初始化，并且`init`函数被执行后，才会进入`main.main`函数，程序开始正常执行。
        - 也就是说，go函数的包引入，是从最底层开始执行的。

## 逃逸分析

一、go怎么确定是否逃逸
1. 指针
   - 很核心的一点就是它有没有被作用域之外所引用。比如说
     - 返回切片指针值
     - 发送指针到channel
2. 不确定类型
   - 使用interface，且通过interface来调用方法

二、为什么需要逃逸

其实就是为了尽可能在栈上分配内存，我们可以反过来想，如果变量都分配到堆上了会出现什么事情？例如：

- 垃圾回收（GC）的压力不断增大 
- 申请、分配、回收内存的系统开销增大（相对于栈）
- 动态分配产生一定量的内存碎片

## Context

1. 原理，使用channel来做信号通信
2. 应用场景
   - RPC应用
   - 超时请求
   - http request 上下文传递数据
   - PipeLine，整条流水线的控制，需要使用上Context。

## 切片与数组

slice本质上其实是对array进一步封装后的结果，其底层是array。两者区别在于，array的长度是固定的，且即使存放的元素是同一类型，比如都是int，都是如果长度不同，从数据的角度来看，依旧会被认为是两种类型的数据。而slice的类型不会受长度影响，同时，slice的长度也不是固定的，可以动态扩容。

## 中间件的实现

1. 以类型的形式实现，利用interface的特性，只要实现了一样的方法，就等于实现了接口

2. 以函数的形式实现，利用go函数作为返回值的特性。

## Sync包

### sync.map

#### 1. 意义

go 内建的map不是线程(goroutine)安全的。在没有sync.Map之前，我们只能利用读写锁来实现，这样可以同时减少Mutex互斥锁带来的读写时的性能。但是，在map的数据非常大的情况下，一把锁会导致大并发的客户端共争一把锁。

#### 2. 优化点

- 空间换时间。 通过冗余的两个数据结构(read、dirty),实现加锁对性能的影响。

- 使用只读数据(read)，避免读写冲突。

- 动态调整，miss次数多了之后，将dirty数据提升为read。

- double-checking。

- 延迟删除。 删除一个键值只是打标记，只有在提升dirty的时候才清理删除的数据。

- 优先从read读取、更新、删除，因为对read的读取不需要锁。


#### 3. 数据结构
 ```go
 type Map struct {
   // 当涉及到dirty数据的操作的时候，需要使用这个锁
   mu Mutex
   // 一个只读的数据结构，因为只读，所以不会有读写冲突。
   // 所以从这个数据中读取总是安全的。
   // 实际上，实际也会更新这个数据的entries,如果entry是未删除的(unexpunged), 并不需要加锁。如果entry已经被删除了，需要加锁，以便更新dirty数据。
   read atomic.Value // readOnly
   // dirty数据包含当前的map包含的entries,它包含最新的entries(包括read中未删除的数据,虽有冗余，但是提升dirty字段为read的时候非常快，不用一个一个的复制，而是直接将这个数据结构作为read字段的一部分),有些数据还可能没有移动到read字段中。
   // 对于dirty的操作需要加锁，因为对它的操作可能会有读写竞争。
   // 当dirty为空的时候， 比如初始化或者刚提升完，下一次的写操作会复制read字段中未删除的数据到这个数据中。
   dirty map[interface{}]*entry
   // 当从Map中读取entry的时候，如果read中不包含这个entry,会尝试从dirty中读取，这个时候会将misses加一，
   // 当misses累积到 dirty的长度的时候， 就会将dirty提升为read,避免从dirty中miss太多次。因为操作dirty需要加锁。
   misses int
  }
 ```

#### 4. 实现关键点

  Load、Store、Delete、Range这四个重点方法，数据操作起点都是read，都要做双检查。
  <font color=red>sync.Map没有len方法！</font>

- 取数操作(Load)   
  - 先从read尝试获取，无需加锁，因为是读操作
  - read获取不到，会从dirty尝试获取，但是需要双检查，需要记录misses
    - 双检查指的是先获取锁之后，再尝试从read获取一次数据先，主要是避免加锁过程过，dirty被提升成了read
    - misses累计到一定数之后，会提升dirty为read，具体实现为直接把dirty赋值给read.m
- 赋值操作(Store)
  - 如果m.read存在这个键，并且这个entry没有被标记删除，尝试直接存储。
  - 如果`m.read`不存在或者已经被标记删除，尝试操作dirty

- 删除操作(Delete)
  - 从m.dirty中删除的话，直接删除即可，就当它没存在过
  - 但是如果是从m.read中删除，并不会直接删除，而是打标记

- 遍历操作(Range)
  - for ... range map是内建的语言特性，所以没有办法使用for range遍历sync.Map
  - sync.Map 内部实现了Range方法，如果dirty中有read中不存在的数据，Range方法调用前可能会做一个m.dirty的提升。

### sync.poll

使用缓存池技术来复用结构体。可以避免大量的创建重复的结构池，减轻GC压力

### sync.once

使用互斥锁，并多一个标记是否已执行过的字段，可以用来实现单例模式。

## GC

### 1. GC原理

1. GC的根本性操作步骤为，暂停程序(Stop the world，简称STW)，然后由垃圾收集器会扫描已经分配的所有对象并回收不再使用的内存空间，清理完毕后，再恢复程序。

### 2. 底层机制发展史
- 传统算法为 标记清除（Mark-Sweep）算法，简单的说，就是先暂停程序，然后把要回收的都标记出来，然后再一次性清洗，清洗完毕再恢复程序；其显而易见的停机耗时就是最大的缺陷。
- 为了优化耗时问题， 三色标记算法 应运而生。此算法采用灰、黑、白三种颜色来对内存现状进行标记，从而提高了标记阶段的性能。
  - 三色解释:
       • 白色对象 — 潜在的垃圾，其内存可能会被垃圾收集器回收；
       • 黑色对象 — 活跃的对象，包括不存在任何引用外部指针的对象以及从根对象可达的对象；
       • 灰色对象 — 活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象；
  - 核心思路:
       • 从灰色对象的集合中选择一个灰色对象并将其标记成黑色；
       • 将黑色对象指向的所有对象都标记成灰色，保证该对象和被该对象引用的对象都不会被回收；
       • 重复上述两个步骤直到对象图中不存在灰色对象；
       • 将白色对象清除掉
- 但是，三色标记算法解决的只是标记效率问题，为了准确的标记，其实还是需要少不了STW步骤，所以只有三色标记算法，并不能根治传统算法的病。为了能在运行过程中做好标记动作，屏障技术出现了！
   - 屏障技术的核心思想为
          • 强三色不变性 — 黑色对象不会直接指向白色对象，只会指向灰色对象或者黑色对象；
          • 弱三色不变性 — 黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径
   - 业界实际可用算法有两种
               • Dijkstra 提出的插入写屏障，是一种相对保守的屏障技术，它会将有存活可能的对象都标记成灰色以满足强三色不变性。
               • Yuasa 提出的删除写屏障，是在删除一个灰色对象指向某个白色对象的指针时触发，通过对此白色对象的灰着色，保证了此白色对象其下游的对象能够在这一次垃圾收集的循环中存活，避免发生悬挂指针以保证用户程序的正确性。
   - 值得注意的是，Go最终使用的是组合 Dijkstra 插入写屏障和 Yuasa 删除写屏障构成了混合写屏障，
- 最后的最后，三色标记 + 屏障技术解决了标记阶段的耗时难题，给我们提供了两个可选项，要么分多次处理，在不占用额外机器计算开销的前提下，将总耗时拉长，但好处是每次暂停时长较短，对系统影响较少；要么是加大机器计算开销，利用多核并发的能力来缩短一次完整GC的耗时。也就是以下两大垃圾收集优化策略：
         • 增量垃圾收集 — 增量地标记和清除垃圾，降低应用程序暂停的最长时间；
         • 并发垃圾收集 — 利用多核的计算资源，在用户程序执行时并发标记和清除垃圾；

### 3. Go最终实现

- 策略选择
  a. Go采用并发垃圾收集的策略
  b. 垃圾收集器本质上多个 Goroutine的协作，通过调用方法触发状态的迁移，进而保障垃圾回收的准确处理。
- 屏障技术选用
  a. Go最终使用的是组合 Dijkstra 插入写屏障和 Yuasa 删除写屏障构成了混合写屏障
- 触发时机
  a. 后台触发
  b. 手动触发
  c. 申请内存
- 是否可回收？(基础条件)
  a. 允许垃圾收集、程序没有崩溃并且没有处于垃圾收集循环
- 处理步骤
  - 清除终止
    - 暂停程序
  - 标记
      • 将状态切换至 _GCmark
      • 开启写屏障、用户协助程序
      • 恢复执行程序，标记进程和用于协助的用户程序会开始并发标记内存中的对象
  - 标记终止
      • 暂停程序，将状态切换至 _GCmarktermination 并关闭辅助标记的用户程序
  - 清除
      • 将状态切换至 _GCoff
      • 关闭写屏障
      • 恢复用户程序
      • 后台并发执行清理
